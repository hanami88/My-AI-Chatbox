import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.schema import HumanMessage, SystemMessage, AIMessage

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Khá»Ÿi táº¡o Groq LLM
llm = ChatGroq(
    groq_api_key=os.getenv("GROQ_API_KEY"),
    model_name="llama-3.1-70b-versatile",  # hoáº·c "mixtral-8x7b-32768"
    temperature=0.7,
    max_tokens=1024
)


def chatbot_don_gian():
    print("ğŸ¤– Chatbot Ä‘Ã£ khá»Ÿi Ä‘á»™ng! GÃµ 'thoat' Ä‘á»ƒ káº¿t thÃºc.")

    # System message Ä‘á»ƒ Ä‘á»‹nh hÆ°á»›ng AI
    messages = [
        SystemMessage(
            content="Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch. HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch thÃ¢n thiá»‡n vÃ  ngáº¯n gá»n.")
    ]

    while True:
        user_input = input("\nğŸ‘¤ Báº¡n: ")

        if user_input.lower() in ['thoat', 'exit', 'bye', 'quit']:
            print("ğŸ¤– Táº¡m biá»‡t!")
            break

        # ThÃªm tin nháº¯n cá»§a user
        messages.append(HumanMessage(content=user_input))

        # Láº¥y pháº£n há»“i tá»« AI
        try:
            response = llm.invoke(messages)
            print(f"ğŸ¤– Bot: {response.content}")

            # ThÃªm pháº£n há»“i AI vÃ o lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n
            messages.append(AIMessage(content=response.content))

        except Exception as e:
            print(f"âŒ Lá»—i: {e}")


if __name__ == "__main__":
    chatbot_don_gian()