import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate

load_dotenv()

# Kh·ªüi t·∫°o Groq LLM
llm = ChatGroq(
    groq_api_key=os.getenv("GROQ_API_KEY"),
    model_name="llama-3.1-70b-versatile",
    temperature=0.7
)

# Template prompt t√πy ch·ªânh
prompt_template = PromptTemplate(
    input_variables=["history", "input"],
    template="""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh v√† h·ªØu √≠ch. H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch th√¢n thi·ªán, chi ti·∫øt v√† ch√≠nh x√°c.

L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán:
{history}

Ng∆∞·ªùi d√πng: {input}
Tr·ª£ l√Ω AI:"""
)

# B·ªô nh·ªõ ƒë·ªÉ l∆∞u l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán (gi·ªØ l·∫°i 10 tin nh·∫Øn g·∫ßn nh·∫•t)
memory = ConversationBufferWindowMemory(k=10)

# T·∫°o chain conversation
conversation = ConversationChain(
    llm=llm,
    memory=memory,
    prompt=prompt_template,
    verbose=False
)


def chatbot_nang_cao():
    print("ü§ñ Chatbot n√¢ng cao ƒë√£ s·∫µn s√†ng! (c√≥ b·ªô nh·ªõ)")
    print("üìù T√¥i s·∫Ω nh·ªõ cu·ªôc tr√≤ chuy·ªán c·ªßa ch√∫ng ta.")
    print("üí° G√µ 'thoat' ƒë·ªÉ k·∫øt th√∫c.\n")

    while True:
        user_input = input("üë§ B·∫°n: ")

        if user_input.lower() in ['thoat', 'exit', 'bye', 'quit']:
            print("ü§ñ T·∫°m bi·ªát! R·∫•t vui ƒë∆∞·ª£c tr√≤ chuy·ªán v·ªõi b·∫°n!")
            break

        try:
            # L·∫•y ph·∫£n h·ªìi t·ª´ conversation chain
            response = conversation.predict(input=user_input)
            print(f"ü§ñ Bot: {response}\n")

        except Exception as e:
            print(f"‚ùå C√≥ l·ªói x·∫£y ra: {e}\n")


if __name__ == "__main__":
    chatbot_nang_cao()